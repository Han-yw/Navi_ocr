Index: src/org/tensorflow/demo/DetectorActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>/*\r\n * Copyright 2016 The TensorFlow Authors. All Rights Reserved.\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *       http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n\r\npackage org.tensorflow.demo;\r\n\r\nimport androidx.fragment.app.Fragment;\r\n\r\nimport android.annotation.TargetApi;\r\nimport android.content.Intent;\r\nimport android.content.IntentSender;\r\nimport android.content.pm.PackageManager;\r\nimport android.graphics.Bitmap;\r\nimport android.graphics.Bitmap.Config;\r\nimport android.graphics.Canvas;\r\nimport android.graphics.Color;\r\nimport android.graphics.Matrix;\r\nimport android.graphics.Paint;\r\nimport android.graphics.Paint.Style;\r\nimport android.graphics.RectF;\r\nimport android.graphics.Typeface;\r\nimport android.icu.text.Edits;\r\nimport android.location.Location;\r\nimport android.location.LocationListener;\r\nimport android.media.ImageReader.OnImageAvailableListener;\r\nimport android.os.Build;\r\nimport android.os.Bundle;\r\nimport android.os.Handler;\r\nimport android.os.Looper;\r\nimport android.os.SystemClock;\r\nimport android.speech.RecognitionListener;\r\nimport android.speech.SpeechRecognizer;\r\nimport android.util.Log;\r\nimport android.util.Size;\r\nimport android.util.TypedValue;\r\nimport android.view.KeyEvent;\r\nimport android.view.LayoutInflater;\r\nimport android.view.View;\r\nimport android.view.ViewGroup;\r\nimport android.widget.Button;\r\nimport android.widget.ImageButton;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.core.app.ActivityCompat;\r\nimport androidx.core.content.ContextCompat;\r\nimport androidx.fragment.app.FragmentPagerAdapter;\r\n\r\nimport com.android.volley.RequestQueue;\r\nimport com.android.volley.Response;\r\nimport com.android.volley.toolbox.Volley;\r\nimport com.google.android.gms.common.api.ResolvableApiException;\r\nimport com.google.android.gms.location.LocationRequest;\r\nimport com.google.android.gms.location.LocationServices;\r\nimport com.google.android.gms.location.LocationSettingsRequest;\r\nimport com.google.android.gms.location.LocationSettingsResponse;\r\nimport com.google.android.gms.location.SettingsClient;\r\nimport com.google.android.gms.tasks.OnFailureListener;\r\nimport com.google.android.gms.tasks.Task;\r\n\r\nimport org.json.JSONArray;\r\nimport org.json.JSONException;\r\nimport org.json.JSONObject;\r\nimport org.tensorflow.demo.OverlayView.DrawCallback;\r\nimport org.tensorflow.demo.env.BorderedText;\r\nimport org.tensorflow.demo.env.ImageUtils;\r\nimport org.tensorflow.demo.env.Logger;\r\nimport org.tensorflow.demo.tracking.MultiBoxTracker;\r\nimport org.tensorflow.demo.vision_module.Compass;\r\nimport org.tensorflow.demo.vision_module.InstanceHashTable;\r\nimport org.tensorflow.demo.vision_module.InstanceTimeBuffer;\r\nimport org.tensorflow.demo.vision_module.MyCallback;\r\nimport org.tensorflow.demo.vision_module.MapRequest;\r\nimport org.tensorflow.demo.vision_module.MyGps;\r\nimport org.tensorflow.demo.vision_module.OcrRequest;\r\nimport org.tensorflow.demo.vision_module.SOTWFormatter;\r\nimport org.tensorflow.demo.vision_module.Sector;\r\nimport org.tensorflow.demo.vision_module.Service;\r\nimport org.tensorflow.demo.vision_module.Voice;\r\nimport org.tensorflow.demo.vision_module.senario;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Iterator;\r\nimport java.util.LinkedList;\r\nimport java.util.List;\r\nimport java.util.Set;\r\nimport java.util.Vector;\r\n\r\n/**\r\n * An activity that uses a TensorFlowMultiBoxDetector and ObjectTracker to detect and then track\r\n * objects.\r\n */\r\npublic class DetectorActivity extends CameraActivity implements OnImageAvailableListener {\r\n\r\n\r\n    private static final Logger LOGGER = new Logger();\r\n\r\n    // Configuration values for tiny-yolo-voc. Note that the graph is not included with TensorFlow and\r\n    // must be manually placed in the assets/ directory by the user.\r\n    // Graphs and models downloaded from http://pjreddie.com/darknet/yolo/ may be converted e.g. via\r\n    // DarkFlow (https://github.com/thtrieu/darkflow). Sample command:\r\n    // ./flow --model cfg/tiny-yolo-voc.cfg --load bin/tiny-yolo-voc.weights --savepb --verbalise\r\n\r\n    private static final String YOLO_MODEL_FILE = \"file:///android_asset/my-tiny-yolo.pb\";\r\n    private static final int YOLO_INPUT_SIZE = 416;\r\n    private static final String YOLO_INPUT_NAME = \"input\";\r\n    private static final String YOLO_OUTPUT_NAMES = \"output\";\r\n    private static final int YOLO_BLOCK_SIZE = 32;\r\n\r\n    private enum DetectorMode {\r\n        YOLO;\r\n    }\r\n\r\n    private static final DetectorMode MODE = DetectorMode.YOLO;\r\n\r\n    // Minimum detection confidence to track a detection.\r\n    public static final float MINIMUM_CONFIDENCE_YOLO = 0.5f;\r\n\r\n    private static final boolean MAINTAIN_ASPECT = MODE == DetectorMode.YOLO;\r\n\r\n    private static final Size DESIRED_PREVIEW_SIZE = new Size(640, 480);\r\n\r\n    private static final boolean SAVE_PREVIEW_BITMAP = false;\r\n    private static final float TEXT_SIZE_DIP = 10;\r\n\r\n    private Integer sensorOrientation;\r\n\r\n    private Classifier detector;\r\n\r\n    private long lastProcessingTimeMs;\r\n    private long lastProcessingTimeMs1;\r\n    private long lastDetectStartTime = 0;\r\n    private Bitmap rgbFrameBitmap = null;\r\n    private Bitmap croppedBitmap = null;\r\n    private Bitmap cropCopyBitmap = null;\r\n    private Bitmap cropSignBitmap = null;\r\n    private float bitmapWidth = 0;\r\n    private float bitmapHeight = 0;\r\n    private int N = 5; // N * N 사분면\r\n\r\n    private static final int BUFFERTIME = 3;\r\n\r\n    private boolean computingDetection = false;\r\n\r\n    private long timestamp = 0;\r\n\r\n    private Matrix frameToCropTransform;\r\n    private Matrix cropToFrameTransform;\r\n\r\n    private MultiBoxTracker tracker;\r\n    private OverlayView trackingOverlay;\r\n\r\n    private byte[] luminanceCopy;\r\n\r\n    private BorderedText borderedText;\r\n\r\n    private RequestQueue requestQueue;\r\n    private LocationRequest locationRequest;\r\n    private MyGps myGps;\r\n    private Service service;\r\n    private Voice voice;\r\n    private Compass compass;\r\n    private SOTWFormatter sotwFormatter;\r\n    private Sector curSector = new Sector(false);\r\n    private boolean dotFlag = false;\r\n    private boolean yoloFirstStartFlag = false;\r\n\r\n    public InstanceMatrix instanceMatrix = new InstanceMatrix();\r\n    public InstanceTimeBuffer instanceTimeBuffer = new InstanceTimeBuffer();\r\n\r\n\r\n    TensorFlowYoloDetector tensorFlowYoloDetector = new TensorFlowYoloDetector();\r\n\r\n\r\n    @Override\r\n    protected void onCreate(final Bundle savedInstanceState) {\r\n        super.onCreate(savedInstanceState);\r\n\r\n\r\n//\r\n        ImageButton detectedClass = findViewById(R.id.cameraclick);\r\n        detectedClass.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n//      Log.i(\"bt\", \"버튼누름\");\r\n                Toast.makeText(getApplicationContext(), tensorFlowYoloDetector.hangul_class, Toast.LENGTH_SHORT).show();\r\n\r\n                LOGGER.i(\"%s  %s\", \"버튼눌러서 나온 값 : \", tensorFlowYoloDetector.hangul_class);\r\n                voice.TTS(\"전방에\" + tensorFlowYoloDetector.hangul_class + \" 가 있습니다.\");\r\n            }\r\n        });\r\n\r\n\r\n        // 5 * 5 분면의 InstanceBuffer 초기화\r\n        instanceMatrix.initMat(5, 5);\r\n\r\n\r\n        // GPS가 꺼져있다면 On Dialog\r\n        createLocationRequest();\r\n        turn_on_GPS_dialog();\r\n\r\n\r\n        //Gps\r\n        myGps = new MyGps(DetectorActivity.this, locationListener);\r\n        new Handler(Looper.getMainLooper()).postDelayed(new Runnable() {\r\n            @Override\r\n            public void run() {\r\n                myGps.startGps(DetectorActivity.this.service);\r\n                Log.e(\"thread\", \"run: start\");\r\n            }\r\n        }, 0);\r\n\r\n        //Compass\r\n        compass = new Compass(this);\r\n        sotwFormatter = new SOTWFormatter(this); // 방향 포맷,,방위각 보고 N,NW ..써주는 친구..\r\n        Compass.CompassListener cl = getCompassListener();\r\n        compass.setListener(cl);\r\n\r\n        // Voice\r\n        voice = new Voice(this, null);\r\n\r\n        // API Server\r\n        requestQueue = Volley.newRequestQueue(DetectorActivity.this);  // 전송 큐\r\n\r\n        // Service\r\n        service = new Service();\r\n\r\n    }\r\n\r\n\r\n    @Override\r\n    public void onPreviewSizeChosen(final Size size, final int rotation) {\r\n        final float textSizePx =\r\n                TypedValue.applyDimension(\r\n                        TypedValue.COMPLEX_UNIT_DIP, TEXT_SIZE_DIP, getResources().getDisplayMetrics());\r\n        borderedText = new BorderedText(textSizePx);\r\n        borderedText.setTypeface(Typeface.MONOSPACE);\r\n\r\n        tracker = new MultiBoxTracker(this);\r\n\r\n        detector = TensorFlowYoloDetector.create(\r\n                getAssets(),\r\n                YOLO_MODEL_FILE,\r\n                YOLO_INPUT_SIZE,\r\n                YOLO_INPUT_NAME,\r\n                YOLO_OUTPUT_NAMES,\r\n                YOLO_BLOCK_SIZE);\r\n\r\n        int cropSize = YOLO_INPUT_SIZE;\r\n\r\n        previewWidth = size.getWidth();\r\n        previewHeight = size.getHeight();\r\n\r\n        sensorOrientation = rotation - getScreenOrientation();\r\n//    LOGGER.i(\"Camera orientation relative to screen canvas: %d\", sensorOrientation);\r\n//\r\n//    LOGGER.i(\"Initializing at size %dx%d\", previewWidth, previewHeight);\r\n        rgbFrameBitmap = Bitmap.createBitmap(previewWidth, previewHeight, Config.ARGB_8888);\r\n        croppedBitmap = Bitmap.createBitmap(cropSize, cropSize, Config.ARGB_8888);\r\n\r\n        frameToCropTransform =\r\n                ImageUtils.getTransformationMatrix(\r\n                        previewWidth, previewHeight,\r\n                        cropSize, cropSize,\r\n                        sensorOrientation, MAINTAIN_ASPECT);\r\n\r\n        cropToFrameTransform = new Matrix();\r\n        frameToCropTransform.invert(cropToFrameTransform);\r\n\r\n        trackingOverlay = (OverlayView) findViewById(R.id.tracking_overlay);\r\n        trackingOverlay.addCallback(\r\n                new DrawCallback() {\r\n                    @Override\r\n                    public void drawCallback(final Canvas canvas) {\r\n                        tracker.draw(canvas);\r\n                        if (isDebug()) {\r\n                            //tracker.drawDebug(canvas);\r\n                        }\r\n                    }\r\n                });\r\n\r\n        addCallback(\r\n                new DrawCallback() {\r\n                    @Override\r\n                    public void drawCallback(final Canvas canvas) {\r\n                        if (!isDebug()) {\r\n                            return;\r\n                        }\r\n\r\n                        final Vector<String> lines = new Vector<String>();\r\n\r\n                        lines.add(\"\");\r\n                        lines.add(\"InstanceTimeBuffer\" + instanceTimeBuffer.getAcumCount());\r\n                        lines.add(\"\");\r\n\r\n                        if (!DetectorActivity.this.instanceTimeBuffer.isEmpty()) {\r\n                            InstanceHashTable lastInstanceBuffer = instanceTimeBuffer.getLast();\r\n                            Iterator iterKey = lastInstanceBuffer.keySet().iterator();\r\n                            while (iterKey.hasNext()) {\r\n                                int nKey = (int) iterKey.next();\r\n                                ArrayList<Classifier.Recognition> recognitionArrayList = lastInstanceBuffer.get(nKey);\r\n                                for (int i = 0; i < recognitionArrayList.size(); i++) {\r\n                                    Classifier.Recognition recog = recognitionArrayList.get(i);\r\n                                    lines.add(recog.getTitle() + \" No.\" + i + \" TimeStamp:\" + recog.getTimeStamp() + \" (\" + recog.getMatIdx(N, N).rowIdx + \",\" + recog.getMatIdx(N, N).colIdx + \")\");\r\n                                }\r\n                            }\r\n                        }\r\n\r\n                        lines.add(\"\");\r\n                        lines.add(\"Compass: \" + sotwFormatter.format(service.getAzimuth()));\r\n                        lines.add(\"\");\r\n                        lines.add(\"GPS\");\r\n                        lines.add(\" Latitude: \" + service.getLatitude());\r\n                        lines.add(\" Longitude: \" + service.getLongitude());\r\n                        lines.add(\"\");\r\n                        lines.add(\"Src Station: \" + service.getSource_Station());\r\n//                        lines.add(\"Src Exit: \" + service.getSource_Exit());\r\n                        lines.add(\"Dst Station: \" + service.getDest_Station());\r\n\r\n//                        lines.add(\"Dst Exit: \" + service.getDest_Exit());\r\n                        lines.add(\"\");\r\n\r\n//                        if (DetectorActivity.this.service.getSectorArrayList().size() > 0) {\r\n//                            String tmp = \"Path\";\r\n//                            for (Sector sec : service.getPath()) {\r\n//                                tmp = tmp + \" -> \" + sec.getIndex();\r\n//                            }\r\n//                            lines.add(tmp);\r\n//                            lines.add(\"Next Sector: \" + service.getCurrent_Sector().getIndex());\r\n//                            lines.add(\"matchingFlag: \" + service.getMatchingFlag());\r\n//                            lines.add(\"가장 근접한 sector: \" + service.idx + \", Score: \" + service.score);\r\n//                            lines.add(\"현재 sector: \" + service.getUserSectorNum());\r\n//                            lines.add(\"Way: \" + service.getWay());\r\n//                            lines.add(\"NextWay: \" + service.getNextWay());\r\n//                            lines.add(\"\");\r\n//                        }\r\n\r\n                        borderedText.drawLines(canvas, 10, canvas.getHeight() - 100, lines);\r\n                    }\r\n                });\r\n    }\r\n\r\n    @Override\r\n    protected void processImage() {\r\n        ++timestamp;\r\n        final long currTimestamp = timestamp;\r\n        byte[] originalLuminance = getLuminance();\r\n        tracker.onFrame(\r\n                previewWidth,\r\n                previewHeight,\r\n                getLuminanceStride(),\r\n                sensorOrientation,\r\n                originalLuminance,\r\n                timestamp);\r\n        trackingOverlay.postInvalidate();\r\n\r\n        // No mutex needed as this method is not reentrant.\r\n        if (computingDetection) {\r\n            readyForNextImage();\r\n            return;\r\n        }\r\n        computingDetection = true;\r\n//    LOGGER.i(\"Preparing image \" + currTimestamp + \" for detection in bg thread.\");\r\n\r\n        rgbFrameBitmap.setPixels(getRgbBytes(), 0, previewWidth, 0, 0, previewWidth, previewHeight);\r\n\r\n        if (luminanceCopy == null) {\r\n            luminanceCopy = new byte[originalLuminance.length];\r\n        }\r\n        System.arraycopy(originalLuminance, 0, luminanceCopy, 0, originalLuminance.length);\r\n        readyForNextImage();\r\n\r\n        final Canvas canvas = new Canvas(croppedBitmap);\r\n        canvas.drawBitmap(rgbFrameBitmap, frameToCropTransform, null);\r\n        // For examining the actual TF input.\r\n        if (SAVE_PREVIEW_BITMAP) {\r\n            ImageUtils.saveBitmap(croppedBitmap);\r\n        }\r\n\r\n        runInBackground(\r\n                new Runnable() {\r\n                    @TargetApi(Build.VERSION_CODES.N)\r\n                    @Override\r\n                    public void run() {\r\n                        if (!DetectorActivity.this.yoloFirstStartFlag) {\r\n                            DetectorActivity.this.yoloFirstStartFlag = true;\r\n                            voice.TTS(\"로딩 완료! Vision, 시작 가능합니다.\");\r\n                        }\r\n                        LOGGER.i(\"Running detection on image \" + currTimestamp);\r\n                        final long startTime = SystemClock.uptimeMillis();\r\n\r\n                        final List<Classifier.Recognition> results = detector.recognizeImage(croppedBitmap);\r\n                        DetectorActivity.this.lastProcessingTimeMs = SystemClock.uptimeMillis() - startTime;\r\n                        if (bitmapHeight == 0 || bitmapWidth == 0) {\r\n                            DetectorActivity.this.bitmapHeight = croppedBitmap.getHeight();\r\n                            DetectorActivity.this.bitmapWidth = croppedBitmap.getWidth();\r\n                            Log.e(\"bitmapSize\", \"width: \" + bitmapWidth);\r\n                            Log.e(\"bitmapSize\", \"height: \" + bitmapWidth);\r\n                            instanceTimeBuffer.setBitmapHeight(DetectorActivity.this.bitmapHeight);\r\n                            instanceTimeBuffer.setBitmapWidth(DetectorActivity.this.bitmapWidth);\r\n                        }\r\n                        // Canvas On/Off 기능 생각해보기\r\n                        cropCopyBitmap = Bitmap.createBitmap(croppedBitmap);\r\n                        final Canvas canvas = new Canvas(cropCopyBitmap);\r\n                        final Paint paint = new Paint();\r\n                        paint.setColor(Color.RED);\r\n                        paint.setStyle(Style.STROKE);\r\n                        paint.setStrokeWidth(2.0f);\r\n\r\n                        float minimumConfidence = MINIMUM_CONFIDENCE_YOLO;\r\n\r\n                        final List<Classifier.Recognition> mappedRecognitions =\r\n                                new LinkedList<Classifier.Recognition>();\r\n\r\n\r\n                        // 일단은 그냥 아무거나 cropSignBitmap에 넣어보자\r\n                        // 제일 처음 뜬 instance crop!!\r\n//            if(results.size() > 0) {\r\n//              RectF cslocation = results.get(0).getLocation();\r\n//              DetectorActivity.this.cropSignBitmap = cropBitmap(croppedBitmap,cslocation);\r\n//            }\r\n\r\n\r\n                        for (final Classifier.Recognition resultb : results) {\r\n                            // dot block이 존재한다면 check\r\n                            Classifier.Recognition result = resultb.clone();\r\n                            if (result.getIdx() == 0) dotFlag = true;\r\n                            curSector.setCurSector(result.getIdx());\r\n\r\n                            //Log.e(\"result\", \"=========================offset? : \" + result.toString());\r\n                            final RectF location = result.getLocation();\r\n\r\n                            instanceMatrix.putRecog(result);\r\n\r\n                            if (location != null && result.getConfidence() >= minimumConfidence) {\r\n                                canvas.drawRect(location, paint);\r\n\r\n                                cropToFrameTransform.mapRect(location);\r\n                                result.setLocation(location);\r\n                                mappedRecognitions.add(result);\r\n//                Log.e(\"mappedRecognitions\", \"=========================mappedRecognitions? : \" + mappedRecognitions + i);\r\n                            }\r\n                        }\r\n\r\n//--------------------------------------Instance Time Buffer 추가 -----------------------------------\r\n\r\n                        // Instance의 클래스 별로 Table 생성, 각 키별로 ArrayList..\r\n                        InstanceHashTable curTimeInstance = new InstanceHashTable();\r\n                        // 현재 발견된 instance를 Table화\r\n                        if (!results.isEmpty()) {\r\n                            for (final Classifier.Recognition result : results) {\r\n                                curTimeInstance.putRecog(result);\r\n                            }\r\n\r\n                            // instanceTimeBuffer는 자동으로 최대 사이즈(getMaxSize)를 유지한다.\r\n                            instanceTimeBuffer.add(curTimeInstance);\r\n\r\n                            Log.e(\"DetectorActivity\", \"instancLast accum: \" + instanceTimeBuffer.getAcumCount() + \" \" + instanceTimeBuffer.getLast().keySet());\r\n                        }\r\n//----------------------------------------------------------------------------------------\r\n\r\n//          시간측정\r\n                        DetectorActivity.this.lastProcessingTimeMs1 += SystemClock.uptimeMillis() - startTime;\r\n                        //Log.e(\"Time\", \"=========================Time? : \" + lastProcessingTimeMs1);\r\n                        // 3초 지날때마다 갱신\r\n                        if (DetectorActivity.this.lastProcessingTimeMs1 >= BUFFERTIME * 1000) {\r\n\r\n\r\n                            // navigate 실행, service is ready는 맵데이터를 받아 왔을때 부터 Ture된다.\r\n//                            if (service != null && service.isReady()) {\r\n//                                try {\r\n//                                    navigate();\r\n//                                } catch (JSONException e) {\r\n//                                    e.printStackTrace();\r\n//                                }\r\n//                            }\r\n\r\n                            // 초기화\r\n                            dotFlag = false;\r\n                            curSector.reset();\r\n                            DetectorActivity.this.lastProcessingTimeMs1 = 0;\r\n\r\n                            instanceMatrix.instanceClear();\r\n                        }\r\n\r\n                        tracker.trackResults(mappedRecognitions, luminanceCopy, currTimestamp);\r\n                        trackingOverlay.postInvalidate();\r\n\r\n                        requestRender();\r\n                        computingDetection = false;\r\n                    }\r\n                });\r\n    }\r\n\r\n    @Override\r\n    protected int getLayoutId() {\r\n        return R.layout.camera_connection_fragment_tracking;\r\n    }\r\n\r\n    @Override\r\n    protected Size getDesiredPreviewFrameSize() {\r\n        return DESIRED_PREVIEW_SIZE;\r\n    }\r\n\r\n    @Override\r\n    public void onSetDebug(final boolean debug) {\r\n        detector.enableStatLogging(debug);\r\n    }\r\n\r\n//--Listener----------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\n    // GPS Location 정보 획득시 리스너 객체\r\n    final LocationListener locationListener = new LocationListener() {\r\n        @Override\r\n        public void onLocationChanged(Location location) {\r\n\r\n            service.setLatitude(location.getLatitude());\r\n            service.setLongitude(location.getLongitude());\r\n\r\n            Log.e(\"t\", \"service 위도: \" + service.getLatitude());\r\n            Log.e(\"t\", \"service 경도: \" + service.getLongitude() + \"\\n..\\n\");\r\n\r\n        }\r\n\r\n        @Override\r\n        public void onStatusChanged(String provider, int status, Bundle extras) {\r\n            Log.e(\"t\", \"startGps: 상태변화\");\r\n        }\r\n\r\n        @Override\r\n        public void onProviderEnabled(String provider) {\r\n            Log.e(\"t\", \"startGps: 사용가능\");\r\n            //myGps.startGps();\r\n        }\r\n\r\n        @Override\r\n        public void onProviderDisabled(String provider) {\r\n            Log.e(\"t\", \"startGps: 사용불가\");\r\n        }\r\n    };\r\n\r\n    public RecognitionListener getRecognitionListner(final MyCallback myCallback) {\r\n        return new RecognitionListener() {\r\n            @Override\r\n            public void onReadyForSpeech(Bundle bundle) {\r\n                Toast.makeText(getApplicationContext(), \"음성인식을 시작합니다.\", Toast.LENGTH_SHORT).show();\r\n\r\n            }\r\n\r\n            @Override\r\n            public void onBeginningOfSpeech() {\r\n\r\n            }\r\n\r\n            @Override\r\n            public void onRmsChanged(float v) {\r\n\r\n            }\r\n\r\n            @Override\r\n            public void onBufferReceived(byte[] bytes) {\r\n\r\n            }\r\n\r\n            @Override\r\n            public void onEndOfSpeech() {\r\n\r\n            }\r\n\r\n            @Override\r\n            public void onError(int i) {\r\n                voice.TTS(\"음성 에러. 다시 눌러주세요\");\r\n                String message;\r\n\r\n                switch (i) {\r\n\r\n                    case SpeechRecognizer.ERROR_AUDIO:\r\n                        message = \"오디오 에러\";\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_CLIENT:\r\n                        message = \"클라이언트 에러\";\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS:\r\n                        message = \"퍼미션없음\";\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_NETWORK:\r\n                        message = \"네트워크 에러\";\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_NETWORK_TIMEOUT:\r\n                        message = \"네트웍 타임아웃\";\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_NO_MATCH:\r\n                        message = \"찾을수 없음\";\r\n                        ;\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_RECOGNIZER_BUSY:\r\n                        message = \"바쁘대\";\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_SERVER:\r\n                        message = \"서버이상\";\r\n                        ;\r\n                        break;\r\n\r\n                    case SpeechRecognizer.ERROR_SPEECH_TIMEOUT:\r\n                        message = \"말하는 시간초과\";\r\n                        break;\r\n\r\n                    default:\r\n                        message = \"알수없음\";\r\n                        break;\r\n                }\r\n                Log.e(\"GoogleActivity\", \"SPEECH ERROR : \" + message);\r\n            }\r\n\r\n            @Override\r\n            public void onResults(Bundle results) {\r\n                myCallback.callbackBundle(results);\r\n            }\r\n\r\n            @Override\r\n            public void onPartialResults(Bundle bundle) {\r\n\r\n            }\r\n\r\n            @Override\r\n            public void onEvent(int i, Bundle bundle) {\r\n\r\n            }\r\n        };\r\n    }\r\n\r\n\r\n//--Function----------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n    /* 한글을 영어로 변환 */\r\n    //초성 - 가(의 ㄱ), 날(ㄴ) 닭(ㄷ)\r\n    public static String[] arrChoSungEng = {\"k\", \"K\", \"n\", \"d\", \"D\", \"r\", \"m\", \"b\", \"B\", \"s\", \"S\",\r\n            \"a\", \"j\", \"J\", \"ch\", \"c\", \"t\", \"p\", \"h\"};\r\n\r\n    //중성 - 가(의 ㅏ), 야(ㅑ), 뺨(ㅑ)\r\n    public static String[] arrJungSungEng = {\r\n            \"a\", \"e\", \"ya\", \"ae\", \"eo\", \"e\", \"yeo\", \"e\", \"o\", \"wa\", \"wae\", \"oe\",\r\n            \"yo\", \"u\", \"wo\", \"we\", \"wi\", \"yu\", \"eu\", \"ui\", \"i\"\r\n    };\r\n\r\n    //종성 - 가(없음), 갈(ㄹ)\r\n    public static String[] arrJongSungEng = {\"\", \"k\", \"K\", \"ks\", \"n\", \"nj\", \"nh\",\r\n            \"d\", \"l\", \"lg\", \"lm\", \"lb\", \"ls\", \"lt\", \"lp\", \"lh\", \"m\", \"b\", \"bs\", \"s\", \"ss\",\r\n            \"ng\", \"j\", \"ch\", \"c\", \"t\", \"p\", \"h\"};\r\n\r\n    //단일 자음 - ㄱ,ㄴ,ㄷ,ㄹ... (ㄸ,ㅃ,ㅉ은 단일자음(초성)으로 쓰이지만 단일자음으론 안쓰임)\r\n    public static String[] arrSingleJaumEng = {\"r\", \"R\", \"rt\", \"s\", \"sw\", \"sg\", \"e\", \"E\", \"f\",\r\n            \"fr\", \"fa\", \"fq\", \"ft\", \"fx\", \"fv\", \"fg\", \"a\", \"q\", \"Q\", \"qt\", \"t\", \"T\", \"d\", \"w\", \"W\",\r\n            \"c\", \"z\", \"x\", \"v\", \"g\"};\r\n\r\n    //어디 지하철 역인지 파악하는 메소드\r\n    public String recognizeStation(String stt_Station) {\r\n        String resultEng = \"\", targetStation = \"\";\r\n\r\n        if (stt_Station.contains(\"역\")) {\r\n            targetStation = stt_Station.split(\"역\")[0];\r\n        } else targetStation = stt_Station;\r\n        Log.e(\"11\", \"stepppp done.\");\r\n\r\n        if (targetStation.contains(\"수\") || targetStation.contains(\"상\")) targetStation = \"상수\";\r\n        else if (targetStation.contains(\"정\") || targetStation.contains(\"합\")) targetStation = \"합정\";\r\n        Log.e(\"한번 가공후\", \"step done...\");\r\n\r\n        Log.e(\"최종결과는?\", targetStation);\r\n        return targetStation;\r\n    }\r\n\r\n    ;\r\n\r\n    //몇번 출구인지 파악하는 메소드\r\n    public String recognizeExit(String stt_Exit) {\r\n        String exitNum = \"\", exitMatch = \"\";\r\n        String targetExit = \"1\";\r\n\r\n        if (stt_Exit.contains(\"번\")) {\r\n            exitNum = stt_Exit.split(\"번\")[0];\r\n        } else exitNum = stt_Exit; // 예시로 srcExitNumber=\"3\" or \"삼\"\r\n        //Log.e(\"한번 가공후\", exitNum);\r\n\r\n        if (exitNum.matches(\"^[0-9]+$\")) {\r\n            Log.e(\"srcExitNumber\", \"숫자임\");\r\n        } else {\r\n            //Log.e(\"srcExitNumber\", \"한글임\");\r\n            exitMatch = exitNum;\r\n            switch (exitMatch) {\r\n                case \"일\":\r\n                    targetExit = \"1\";\r\n                    break;\r\n                case \"이\":\r\n                    targetExit = \"2\";\r\n                    break;\r\n                case \"삼\":\r\n                case \"산\":\r\n                    targetExit = \"3\";\r\n                    break;\r\n                case \"사\":\r\n                    targetExit = \"4\";\r\n                    break;\r\n                case \"오\":\r\n                    targetExit = \"5\";\r\n                    break;\r\n                case \"육\":\r\n                    targetExit = \"6\";\r\n                    break;\r\n                case \"칠\":\r\n                case \"친\":\r\n                    targetExit = \"7\";\r\n                    break;\r\n                case \"팔\":\r\n                case \"판\":\r\n                case \"팜\":\r\n                    targetExit = \"8\";\r\n                    break;\r\n                case \"구\":\r\n                    targetExit = \"9\";\r\n                    break;\r\n                case \"십\":\r\n                    targetExit = \"10\";\r\n                    break;\r\n            }\r\n            exitNum = targetExit;\r\n        }\r\n        return exitNum;\r\n    }\r\n\r\n    ;\r\n\r\n    private int initCompletedStatus = 0;\r\n\r\n\r\n    // 서비스에 필요한 변수들을 초기화한 후, 안내 시작 함수!\r\n    public void initService(int status, final MyCallback myCallback) {\r\n\r\n        final RecognitionListener sourceStationVoiceListener;\r\n        final RecognitionListener destStationVoiceListener;\r\n        final RecognitionListener confirmVoiceListener;\r\n        // final RecognitionListener destExitVoiceListener;\r\n        // final RecognitionListener sourceExitVoiceListener;\r\n\r\n        // 마지막 변수 확정 리스너 -> 네, 아니요 답변에 따라, 재귀함수 시작 or navigate 함수 시작.\r\n        confirmVoiceListener = getRecognitionListner(new MyCallback() {\r\n            @Override\r\n            public void callback() {\r\n\r\n            }\r\n\r\n\r\n            @Override\r\n            public void callbackBundle(Bundle results) {\r\n                String key = \"\";\r\n                key = SpeechRecognizer.RESULTS_RECOGNITION;\r\n                ArrayList<String> mResult = results.getStringArrayList(key);\r\n\r\n                String answer = mResult.get(0);\r\n                Log.e(\"v\", \"answer: \" + answer);\r\n\r\n                try {\r\n                    Thread.sleep(2000);\r\n\r\n                    if (answer.charAt(0) == '아' && answer.charAt(1) == '니')     // 아니오 라고 말했을때\r\n                        DetectorActivity.this.initCompletedStatus = 0;\r\n//                    if (DetectorActivity.this.initCompletedStatus == 6) {\r\n//                        voice.TTS(\"다시 버튼을 눌러 역을 설정해주세요\");\r\n//                    }\r\n\r\n                    else if (answer.charAt(0) != '네' && answer.charAt(0) != '내' && answer.charAt(0) != '예') { //대답이 애매하거나 다른대답일때\r\n                        // 출발지, 도착지가 제대로 체크되지 않았다면, 함수 다시 시작!\r\n                        voice.TTS(\"다시 버튼을 눌러주세요.\");\r\n                    } else {\r\n                        //제대로 체크됬다면 확정짓고 출발역의 맵데이터를 가져온다.\r\n                        Log.e(\"v\", \"Result src & dst: \" + service.getSource_Station() + \" \" + service.getDest_Station());\r\n                        Toast.makeText(DetectorActivity.this, \"출발역 = \" + service.getSource_Station() + \"\\n 도착역 = \" + service.getDest_Station(), Toast.LENGTH_SHORT).show();\r\n\r\n                        DetectorActivity.this.initCompletedStatus = 0;\r\n\r\n//                        if (DetectorActivity.this.initCompletedStatus == 5) {\r\n//                            voice.TTS(\"경로안내를 시작합니다. \");\r\n//                        }\r\n\r\n\r\n                        // ~~~~\r\n\r\n//                         맵데이터를 서비스에 셋팅을 완료한 후 navigate를 실행하기 위해, callback 함수를 통해 사용한다.\r\n\r\n\r\n\r\n                    }\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        });\r\n\r\n//         도착 출구 리스너\r\n//        destExitVoiceListener = getRecognitionListner(new MyCallback() {\r\n//            @Override\r\n//            public void callback() {\r\n//\r\n//            }\r\n//\r\n//            @Override\r\n//            public void callbackBundle(Bundle results) {\r\n//                String key = \"\", stt_dstExit = \"\";\r\n//                key = SpeechRecognizer.RESULTS_RECOGNITION;\r\n//                ArrayList<String> mResult = results.getStringArrayList(key);\r\n//                stt_dstExit = mResult.get(0);\r\n//                stt_dstExit = recognizeExit(stt_dstExit);\r\n//                service.setDest_Exit(stt_dstExit);\r\n////                Log.e(\"v\", \"Destination Exit onResults: \" + service.getDest_Exit());\r\n//\r\n//                DetectorActivity.this.initCompletedStatus = 4;\r\n//\r\n//                try {\r\n//                    Thread.sleep(1000);\r\n//                    voice.TTS(service.getSource_Station() + \"역에서 출발하여 \" +\r\n//                            service.getDest_Station() + \"역으로 도착이 맞습니까? 네, 아니요로 대답해주세요.\");\r\n//                    voice.setRecognitionListener(confirmVoiceListener);\r\n//                    Thread.sleep(8200);\r\n//                    voice.STT();\r\n//                } catch (InterruptedException e) {\r\n//                    e.printStackTrace();\r\n//                }\r\n//            }\r\n//        });\r\n\r\n        // 도착역 리스너\r\n        destStationVoiceListener = getRecognitionListner(new MyCallback() {\r\n            @Override\r\n            public void callback() {\r\n\r\n            }\r\n\r\n            @Override\r\n            public void callbackBundle(Bundle results) {\r\n\r\n                String key = \"\", stt_dstStation = \"\";\r\n\r\n                key = SpeechRecognizer.RESULTS_RECOGNITION;\r\n                ArrayList<String> mResult = results.getStringArrayList(key);\r\n                stt_dstStation = mResult.get(0);\r\n                stt_dstStation = recognizeStation(stt_dstStation);\r\n\r\n                service.setDest_Station(stt_dstStation);\r\n                Log.e(\"v\", \"End Station onResults: \" + service.getDest_Station());\r\n\r\n\r\n                try {\r\n                    Thread.sleep(1000);\r\n                    voice.TTS(service.getSource_Station() + \"역에서 출발하여 \" +\r\n                            service.getDest_Station() + \"역으로 도착이 맞습니까? 네, 아니요로 대답해주세요.\");\r\n                    voice.setRecognitionListener(confirmVoiceListener);\r\n                    Thread.sleep(8200);\r\n                    voice.STT();\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n\r\n\r\n//                try {\r\n//                    Thread.sleep(2000);\r\n//\r\n////                    voice.setRecognitionListener(destExitVoiceListener);\r\n//                    Thread.sleep(2000);\r\n//                    voice.STT();\r\n//                } catch (InterruptedException e) {\r\n//                    e.printStackTrace();\r\n//                }\r\n            }\r\n        });\r\n\r\n        // 출발 출구 리스너\r\n//        sourceExitVoiceListener = getRecognitionListner(new MyCallback() {\r\n//            @Override\r\n//            public void callback() {\r\n//\r\n//            }\r\n//\r\n//            @Override\r\n//            public void callbackBundle(Bundle results) {\r\n//                String key = \"\", stt_srcExit = \"\";\r\n//\r\n//                key = SpeechRecognizer.RESULTS_RECOGNITION;\r\n//                ArrayList<String> mResult = results.getStringArrayList(key);\r\n//                stt_srcExit = mResult.get(0);\r\n//                stt_srcExit = recognizeExit(stt_srcExit);//모든 인식 경우에 대해 출구 결과값을 하나로 도출해냄\r\n//                service.setSource_Exit(stt_srcExit);\r\n////        service.setCurrent_Sector(srcExitNumber); // 현재 Sector로 입력\r\n////        service.setNext_Sector_Index(0);\r\n//\r\n//                Log.e(\"v\", \"Start Exit onResults: \" + service.getSource_Exit());\r\n//\r\n//                DetectorActivity.this.initCompletedStatus = 2;\r\n//\r\n//                try {\r\n//                    Thread.sleep(2000);\r\n//                } catch (InterruptedException e) {\r\n//                    e.printStackTrace();\r\n//                }\r\n//                voice.TTS(senario.destStationString);\r\n//                voice.setRecognitionListener(destStationVoiceListener);\r\n//                try {\r\n//                    Thread.sleep(2000);\r\n//                } catch (InterruptedException e) {\r\n//                    e.printStackTrace();\r\n//                }\r\n//                voice.STT();\r\n//            }\r\n//        });\r\n\r\n        //first step\r\n\r\n\r\n        // 출발역 리스너\r\n        sourceStationVoiceListener = getRecognitionListner(new MyCallback() {\r\n            @Override\r\n            public void callback() {\r\n            }\r\n\r\n            @Override\r\n            public void callbackBundle(Bundle results) {\r\n                String key = \"\", stt_srcStation = \"\";\r\n\r\n                key = SpeechRecognizer.RESULTS_RECOGNITION;\r\n                ArrayList<String> mResult = results.getStringArrayList(key);\r\n                stt_srcStation = mResult.get(0);\r\n                stt_srcStation = recognizeStation(stt_srcStation);//입력받은 단어 파싱\r\n                service.setSource_Station(stt_srcStation);\r\n                Log.e(\"v\", \"Start Station onResults: \" + service.getSource_Station()); //입력값 파싱 후 역 이름 로그 찍어보기\r\n\r\n                DetectorActivity.this.initCompletedStatus = 1;\r\n\r\n                try {\r\n                    Thread.sleep(2000);\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n                voice.TTS(senario.destStationString);\r\n//\r\n                voice.setRecognitionListener(destStationVoiceListener);\r\n                try {\r\n                    Thread.sleep(2000);\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n                voice.STT();\r\n            }\r\n        });\r\n        ArrayList<RecognitionListener> ListenerArray = new ArrayList<RecognitionListener>(Arrays.asList(sourceStationVoiceListener,\r\n                destStationVoiceListener, confirmVoiceListener));\r\n\r\n        // init 시작\r\n        try {\r\n            voice.setRecognitionListener(ListenerArray.get(status));\r\n            if (status == 4) {\r\n                voice.TTS(service.getSource_Station() + \"역에서 출발, \" +\r\n                        service.getDest_Station() + \"역도착이 맞습니까? 네, 아니요로 대답해주세요.\");\r\n                Thread.sleep(8200);\r\n            } else {\r\n                voice.TTS(senario.getI(status));\r\n                Thread.sleep(2500);\r\n            }\r\n\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        }\r\n        voice.STT();\r\n    }\r\n\r\n    public void announceInstance() {\r\n        ArrayList<Classifier.Recognition> annouceAbleInstance = instanceTimeBuffer.getAnnouncealbeInstance(SystemClock.currentThreadTimeMillis());\r\n        for (Classifier.Recognition instance : annouceAbleInstance)\r\n            while (true) {\r\n                if (!voice.isSpeaking()) {\r\n                    instance.Announce(voice);\r\n                    break;\r\n                }\r\n            }\r\n        // ...\r\n    }\r\n\r\n//    public int matchSector() throws JSONException {\r\n//        // GPS Update후 비교\r\n//        myGps.startGps(DetectorActivity.this.service);\r\n//        Log.e(\"gps\", \"gps: \" + DetectorActivity.this.service.getLatitude() + \",  \" + DetectorActivity.this.service.getLongitude());\r\n//\r\n//        // Instance를 통해 sector 찾기\r\n//        DetectorActivity.this.service.score = -100;\r\n//        int idx = 0;\r\n//        for (int i = 5; i <= DetectorActivity.this.service.getSectorArrayListSize(); i++) {\r\n//            if (i == 6) continue;\r\n//            // i번째 Sector와 nextSector의 Instance들 비교해서 점수 반환\r\n//            int score = DetectorActivity.this.service.compareInstance(DetectorActivity.this.service.getMapdataFromIdx(i),\r\n//                    curSector);\r\n//            Log.e(\"score\", i + \"번째 score: \" + score);\r\n//            if (DetectorActivity.this.service.score < score) {\r\n//                DetectorActivity.this.service.score = score; // maxScore값 변경\r\n//                idx = i; // 가장 가까운 위치의 Sector 번호 저장\r\n//            }\r\n//        }\r\n//        service.idx = idx;\r\n//        DetectorActivity.this.service.setUserSectorNum(0);\r\n//        // Sector 맞다면\r\n//        if (DetectorActivity.this.service.score > 0) {\r\n//            int current_Sector = DetectorActivity.this.service.getMapdataFromIdx(idx).getIndex();\r\n//            DetectorActivity.this.service.setUserSectorNum(current_Sector);\r\n//            if (current_Sector == DetectorActivity.this.service.getCurrent_Sector().getIndex()) {\r\n//                // 가까운 Sector와 Path에서 nextSector의 번호 비교\r\n//                if (DetectorActivity.this.service.setCurrentSectorToNext()) return 2;\r\n//                // 매칭만 된 경우\r\n//                service.setCur_Idx(idx);\r\n//                return 1;\r\n//            }\r\n//        }\r\n//\r\n//        // 매칭 안된 경우\r\n//        return 0;\r\n//    }\r\n\r\n    final public static String[] WAY = {\"우측\", \"우측\", \"우측\", \"우측\", \"뒤\", \"좌측\", \"좌측\", \"좌측\"};\r\n\r\n//    public void navigate() throws JSONException {\r\n//\r\n//        // 각 스텝은 몇초마다 실행될지도 정해야할듯?\r\n//        // 전부 3초마다 매번 실행되면 앱이 너무 시끄러울듯!\r\n//\r\n//        announceInstance();\r\n//        // OCR send();\r\n//\r\n//        // dot block이 있다면 섹터 여부 확인\r\n//        // 목적지 도착 2반환, 매칭만 된 경우 1반환, 매칭 안된 경우 0반환\r\n//        service.setMatchingFlag(-1);\r\n//        if (dotFlag) service.setMatchingFlag(matchSector());\r\n//        Log.e(\"matchingSector\", \"matchingSector: \" + service.getMatchingFlag());\r\n//\r\n//        // 매칭 된 경우 방향 정하기\r\n//        if (DetectorActivity.this.service.getMatchingFlag() == 1) {\r\n//            if (service.getCur_Idx() == 8) {\r\n//                voice.TTS(\"좌측 전방에 개찰구가 있습니다.\");\r\n//            } else if (service.getCur_Idx() == 9) {\r\n//                voice.TTS(\"우측으로 블럭따라 유턴하세요.\");\r\n//            } else {\r\n//                // index 는 0~7, N 방향부터 시계방향으로\r\n//                int index = DetectorActivity.this.sotwFormatter.whereUserGo(DetectorActivity.this.service.getAzimuth(), DetectorActivity.this.service.getWay());\r\n//                Log.e(\"wayIndex\", \"wayIndex: \" + index + \", \" + WAY[index]);\r\n////      // {\"앞\", \"우측앞\", \"우\", \"우측뒤\", \"뒤\", \"좌측뒤\", \"좌\", \"좌측앞\"} 으로 변환\r\n////      DetectorActivity.this.service.setNextWay(WAY[index] + \"으로 가세요. \");\r\n//                DetectorActivity.this.service.setNextWay(\"matching 되었습니다!\" + WAY[index] + \"으로 가세요. \");\r\n//                voice.TTS(\"\" + WAY[index] + \"으로 가세요.\");\r\n//            }\r\n//        }\r\n//\r\n//\r\n//        // 목적지 도착 서비스 종료 TTS 구현\r\n//        else if (service.getMatchingFlag() == 2) {\r\n//            voice.TTS(\"좌측 합정방향입니다.\");\r\n//            DetectorActivity.this.service.setNextWay(\"탑승장입니다.\");\r\n//        } else {\r\n//            DetectorActivity.this.service.setNextWay(\"길찾기 중...\");\r\n//        }\r\n//    }\r\n\r\n    // MapData를 서버로 부터 얻어서 Service 객체에 셋\r\n//    public void getMapData_To_Service_From_Server(String stationName, final MyCallback myCallback) {\r\n//        Log.e(\"t\", \"GET : /mapdata/\" + stationName);\r\n//\r\n//        // Server에 셋팅하기 위한 리스너\r\n//        Response.Listener<JSONArray> jsonArrayListener = new Response.Listener<JSONArray>() {\r\n//            @Override\r\n//            public void onResponse(JSONArray response) {\r\n//                ArrayList<Sector> tmpMapdataList = new ArrayList<Sector>();\r\n//\r\n//                for (int i = 0; i < response.length(); i++) {\r\n//                    try {\r\n//                        tmpMapdataList.add(new Sector(response.getJSONObject(i)));\r\n//                    } catch (JSONException e) {\r\n//                        e.printStackTrace();\r\n//                    }\r\n//                }\r\n//\r\n//                DetectorActivity.this.service.setSectorArrayList(tmpMapdataList);\r\n//\r\n//                // 경로 설정\r\n//                try {\r\n//                    DetectorActivity.this.service.setPath(service.getSource_Exit(), service.getDest_Exit());\r\n//                } catch (JSONException e) {\r\n//                    e.printStackTrace();\r\n//                }\r\n//\r\n//\r\n//                if (myCallback != null) myCallback.callback();\r\n//            } //onResponse\r\n//        };\r\n//\r\n//        // Map api에 전송\r\n//        MapRequest jsonRequest = new MapRequest(stationName, jsonArrayListener);\r\n//        this.requestQueue.add(jsonRequest);\r\n//    }\r\n\r\n    // OcrString을 얻어서 TTS\r\n    public void getOcrString(Bitmap bitmap, final Response.Listener<JSONObject> ocrListener) {\r\n        Log.e(\"t\", \"POST : /ocr\");\r\n\r\n        OcrRequest ocrRequest = new OcrRequest(bitmap, ocrListener);\r\n        this.requestQueue.add(ocrRequest);\r\n    }\r\n\r\n    private Compass.CompassListener getCompassListener() {\r\n        return new Compass.CompassListener() {\r\n            @Override\r\n            public void onNewAzimuth(final float azimuth) {\r\n                DetectorActivity.this.service.setAzimuth(azimuth);\r\n            }\r\n        };\r\n    }\r\n\r\n    Bitmap cropBitmap(Bitmap bitmap, RectF location) {\r\n        return Bitmap.createBitmap(bitmap, (int) location.left, (int) location.top, (int) (location.right - location.left), (int) (location.bottom - location.top));\r\n    }\r\n\r\n\r\n    @Override\r\n    public boolean onKeyDown(final int keyCode, final KeyEvent event) {\r\n        if (keyCode == KeyEvent.KEYCODE_VOLUME_UP\r\n                || keyCode == KeyEvent.KEYCODE_BUTTON_L1 || keyCode == KeyEvent.KEYCODE_DPAD_CENTER) {\r\n            this.debug = !this.debug;\r\n            requestRender();\r\n            onSetDebug(debug);\r\n            return true;\r\n        } else if (keyCode == KeyEvent.KEYCODE_VOLUME_DOWN) {\r\n\r\n            //비트맵 처리 한번 해보기!\r\n//      Bitmap bitmap;\r\n//      if(cropSignBitmap == null)\r\n//        bitmap = BitmapFactory.decodeResource(getResources(),R.drawable.ocrtest);\r\n//      else\r\n//        bitmap = cropSignBitmap;\r\n//\r\n//        getOcrString(bitmap, new Response.Listener<JSONObject>() {\r\n//        @Override\r\n//        public void onResponse(JSONObject response) {\r\n//          Log.e(\"h\", \"OCR Response: \" + response.toString());\r\n//          try {\r\n//            voice.TTS(response.getString(\"text\"));\r\n//          } catch (JSONException e) {\r\n//            e.printStackTrace();\r\n//          }\r\n//        }\r\n//      });\r\n\r\n\r\n            //  서비스를 위한 초기화 작업 시작\r\n\r\n            initService(initCompletedStatus, new MyCallback() {\r\n                @Override\r\n                public void callback() {\r\n                    Log.e(\"n\", \"Navigate 시작\");\r\n                    voice.TTS(service.getSource_Station() + \"에서 \" + service.getDest_Station() + \"까지 경로 안내를 시작합니다.\");\r\n//                    service.setReadyFlag(true);\r\n                }\r\n\r\n                @Override\r\n                public void callbackBundle(Bundle result) {\r\n\r\n                }\r\n            });\r\n\r\n            //debugSangsuMapdata();\r\n\r\n            return true;\r\n        }\r\n        return super.onKeyDown(keyCode, event);\r\n    }\r\n\r\n\r\n//    public void debugSangsuMapdata() {\r\n//        service.setDest_Station(\"상수\");\r\n//        service.setSource_Station(\"합정\");\r\n//        service.setSource_Exit(\"2\");\r\n//        service.setDest_Exit(\"3\");\r\n//        getMapData_To_Service_From_Server(\"sangsu\", new MyCallback() {\r\n//            @Override\r\n//            public void callback() {\r\n//                Log.e(\"n\", \"Navigate 시작\");\r\n//                voice.TTS(service.getSource_Station() + \"에서 \" + service.getDest_Station() + \"까지 경로 안내를 시작합니다.\");\r\n//                service.setReadyFlag(true);\r\n//            }\r\n//\r\n//            @Override\r\n//            public void callbackBundle(Bundle results) {\r\n//\r\n//            }\r\n//        });\r\n//    }\r\n\r\n    // GPS 꺼져있을 경우 alert dialog\r\n    protected void createLocationRequest() {\r\n        locationRequest = LocationRequest.create();\r\n        locationRequest.setInterval(10000);\r\n        locationRequest.setFastestInterval(5000);\r\n        locationRequest.setPriority(LocationRequest.PRIORITY_HIGH_ACCURACY);\r\n    }\r\n\r\n    //  GPS 켜는 dialog 뛰우기\r\n    protected void turn_on_GPS_dialog() {\r\n        LocationSettingsRequest.Builder builder = new LocationSettingsRequest.Builder()\r\n                .addLocationRequest(locationRequest);\r\n\r\n        SettingsClient client = LocationServices.getSettingsClient(DetectorActivity.this);\r\n        Task<LocationSettingsResponse> task = client.checkLocationSettings(builder.build());\r\n\r\n        //GPS get에 실패시 (GPS가 꺼져있는 경우)\r\n        task.addOnFailureListener(DetectorActivity.this, new OnFailureListener() {\r\n            @Override\r\n            public void onFailure(@NonNull Exception e) {\r\n                if (e instanceof ResolvableApiException) {\r\n                    // Location settings are not satisfied, but this can be fixed\r\n                    // by showing the user a dialog.\r\n                    try {\r\n                        // Show the dialog by calling startResolutionForResult(),\r\n                        // and check the result in onActivityResult().\r\n                        ResolvableApiException resolvable = (ResolvableApiException) e;\r\n                        resolvable.startResolutionForResult(DetectorActivity.this,\r\n                                0x1);\r\n                    } catch (IntentSender.SendIntentException sendEx) {\r\n                        // Ignore the error.\r\n                    } finally {\r\n\r\n                        myGps.startGps(DetectorActivity.this.service);\r\n                        // GPS를 켜고나면 다시 재부팅하라는 안내가 있어야함\r\n                        // GPS를 중간에\r\n                    }\r\n                }\r\n            }\r\n        });\r\n    }//turn_on_gps end\r\n\r\n\r\n    @Override\r\n    public void onStart() {\r\n        super.onStart();\r\n        if (Build.VERSION.SDK_INT >= 23 &&\r\n                ContextCompat.checkSelfPermission(getApplicationContext(), android.Manifest.permission.ACCESS_FINE_LOCATION) != PackageManager.PERMISSION_GRANTED) {\r\n            ActivityCompat.requestPermissions(DetectorActivity.this, new String[]{android.Manifest.permission.ACCESS_FINE_LOCATION},\r\n                    0);\r\n        }\r\n        Log.d(\"compass\", \"start compass\");\r\n        compass.start();\r\n    }\r\n\r\n    @Override\r\n    public void onPause() {\r\n        super.onPause();\r\n        compass.stop();\r\n    }\r\n\r\n    @Override\r\n    public void onResume() {\r\n        super.onResume();\r\n        compass.start();\r\n    }\r\n\r\n    @Override\r\n    public void onStop() {\r\n        super.onStop();\r\n        Log.d(\"compass\", \"stop compass\");\r\n        compass.stop();\r\n    }\r\n\r\n    @Override\r\n    public void onDestroy() {\r\n        super.onDestroy();\r\n        voice.close();\r\n    }\r\n\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- src/org/tensorflow/demo/DetectorActivity.java	(revision 9f8c90c3fa46add5315ede0f5e56da423acb3f43)
+++ src/org/tensorflow/demo/DetectorActivity.java	(date 1626682882538)
@@ -114,7 +114,7 @@
     // DarkFlow (https://github.com/thtrieu/darkflow). Sample command:
     // ./flow --model cfg/tiny-yolo-voc.cfg --load bin/tiny-yolo-voc.weights --savepb --verbalise
 
-    private static final String YOLO_MODEL_FILE = "file:///android_asset/my-tiny-yolo.pb";
+    private static final String YOLO_MODEL_FILE = "file:///android_asset/hanium_subway_items.pb";
     private static final int YOLO_INPUT_SIZE = 416;
     private static final String YOLO_INPUT_NAME = "input";
     private static final String YOLO_OUTPUT_NAMES = "output";
@@ -202,7 +202,7 @@
                 voice.TTS("전방에" + tensorFlowYoloDetector.hangul_class + " 가 있습니다.");
             }
         });
-
+        
 
         // 5 * 5 분면의 InstanceBuffer 초기화
         instanceMatrix.initMat(5, 5);
